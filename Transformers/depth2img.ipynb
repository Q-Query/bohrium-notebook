{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Text-guided depth-to-image generation","metadata":{}},{"cell_type":"markdown","source":"> 最后一次修改: [dingzh@dp.tech](mailto:dingzh@dp.tech)\n>\n> 描述: 本教程主要参考 [hugging face notebook](https://github.com/huggingface/notebooks/blob/main/diffusers_doc/en/depth2img.ipynb)，可在 Bohrium Notebook 上直接运行。你可以点击界面上方蓝色按钮 `开始连接`，选择 `bohrium-notebook:2023-04-07` 镜像及任意一款`GPU`节点配置，稍等片刻即可运行。\n> 如您遇到任何问题，请联系 [bohrium@dp.tech](mailto:bohrium@dp.tech) 。\n>\n> 共享协议: 本作品采用[知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)进行许可。","metadata":{}},{"cell_type":"markdown","source":"The [StableDiffusionDepth2ImgPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/depth2img#diffusers.StableDiffusionDepth2ImgPipeline) lets you pass a text prompt and an initial image to condition the generation of new images. In addition, you can also pass a `depth_map` to preserve the image structure. If no `depth_map` is provided, the pipeline automatically predicts the depth via an integrated [depth-estimation model](https://github.com/isl-org/MiDaS).\n\nStart by creating an instance of the [StableDiffusionDepth2ImgPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/depth2img#diffusers.StableDiffusionDepth2ImgPipeline):","metadata":{}},{"cell_type":"code","source":"pip install diffusers transformers accelerate","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nos.environ['HTTP_PROXY'] = 'http://ga.dp.tech:8118'\nos.environ['HTTPS_PROXY'] = 'http://ga.dp.tech:8118'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport requests\nfrom PIL import Image\n\nfrom diffusers import StableDiffusionDepth2ImgPipeline\n\npipe = StableDiffusionDepth2ImgPipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-2-depth\",\n    torch_dtype=torch.float16,\n).to(\"cuda\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now pass your prompt to the pipeline. You can also pass a `negative_prompt` to prevent certain words from guiding how an image is generated:","metadata":{}},{"cell_type":"code","source":"url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\ninit_image = Image.open(requests.get(url, stream=True).raw)\nprompt = \"two tigers\"\nn_prompt = \"bad, deformed, ugly, bad anatomy\"\nimage = pipe(prompt=prompt, image=init_image, negative_prompt=n_prompt, strength=0.7).images[0]\nimage","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"| Input                                                                           | Output                                                                                                                                |\n|---------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|\n| <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/coco-cats.png\" width=\"500\"/> | <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/depth2img-tigers.png\" width=\"500\"/> |\n\nPlay around with the Spaces below and see if you notice a difference between generated images with and without a depth map!\n\n<iframe\n\tsrc=\"https://radames-stable-diffusion-depth2img.hf.space\"\n\tframeborder=\"0\"\n\twidth=\"850\"\n\theight=\"500\"\n></iframe>","metadata":{}}]}