{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速开始 PyTorch｜使用 Python 建立深度学习模型\n",
    "\n",
    "> 作者: Haohui Que [quehaohui@dp.tech](mailto:quehaohui@dp.tech)\n",
    ">\n",
    "> 创建日期: 2023-03-11 19:13\n",
    ">\n",
    "> 最后一次修改: Haohui Que [quehaohui@dp.tech](mailto:quehaohui@dp.tech), Yuzhi Zhang [zhangyz@dp.tech](mailto:zhangyz@dp.tech)\n",
    ">\n",
    "> 最后一次修改时间: 2023-03-12 18:36\n",
    ">\n",
    "> 目录: /Proem/PyTorch_Deep_Learning_Model_Tutorial\n",
    ">\n",
    "> 描述: 本教程可在 Bohrium Notebook 上直接运行，您可以点击界面上方蓝色按钮 `开始连接`，选择 `notebook-pytorch:1.13.0` 镜像及任何一款计算机型，稍等片刻即可运行。\n",
    "> 如您遇到任何问题，请您联系 [bohrium@dp.tech](mailto:bohrium@dp.tech) 。\n",
    ">\n",
    "> 共享协议: 本作品采用[知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)进行许可。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目标\n",
    "\n",
    "> **掌握使用 PyTorch 建立深度学习模型的范式周期，并跟随完整案例学习如何应用于预测任务。**\n",
    "\n",
    "在学习本教程后，您将能够：\n",
    "\n",
    "- 了解 Torch 和 PyTorch 的区别，安装 PyTorch 并验证其运行。\n",
    "\n",
    "- 通过五个步骤了解建立、拟合和验证 PyTorch 模型的生命周期。\n",
    "\n",
    "- 掌握如何为回归、分类预测任务建立 PyTorch 深度学习模型。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "\n",
    "* 1 [背景知识](#background)\n",
    "* 2 [实践](#practice)\n",
    "  * 2.1 什么是 PyTorch\n",
    "    * 2.1.1 Torch 与 PyTorch\n",
    "    * 2.1.2 How to Install PyTorch\n",
    "    * 2.1.3 How to Confirm PyTorch Is Installed\n",
    "  * 2.2 PyTorch Deep Learning Model Life-Cycle\n",
    "    * 2.2.1 Step 1: Prepare the Data\n",
    "    * 2.2.2 Step 2: Define the Model\n",
    "    * 2.2.3 Step 3: Train the Model\n",
    "    * 2.2.4 Step 4: Evaluate the Model\n",
    "    * 2.2.5 Step 5: Make Predictions\n",
    "  * 2.3 How to Develop PyTorch Deep Learning Models\n",
    "    * 2.3.1 How to Develop an MLP for Binary Classification\n",
    "    * 2.3.2 How to Develop an MLP for Multiclass Classification\n",
    "    * 2.3.3 How to Develop an MLP for Regression\n",
    "    * 2.3.4 How to Develop a CNN for Image Classification\n",
    "* 3 [总结](#summary)\n",
    "* 4 [推荐阅读](#furtherreading)\n",
    "* 5 [参考](references)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 背景知识<a id ='background'></a>\n",
    "\n",
    "**阅读该教程【最多】约需 60 分钟。**\n",
    "\n",
    "You do not need to understand everything (at least not right now). Your goal is to run through the tutorial end-to-end and get a result. You do not need to understand everything on the first pass. List down your questions as you go. Make heavy use of the API documentation to learn about all of the functions that you’re using.\n",
    "\n",
    "You do not need to know the math first. Math is a compact way of describing how algorithms work, specifically tools from linear algebra, probability, and calculus. These are not the only tools that you can use to learn how algorithms work. You can also use code and explore algorithm behavior with different inputs and outputs. Knowing the math will not tell you what algorithm to choose or how to best configure it. You can only discover that through carefully controlled experiments.\n",
    "\n",
    "You do not need to know how the algorithms work. It is important to know about the limitations and how to configure deep learning algorithms. But learning about algorithms can come later. You need to build up this algorithm knowledge slowly over a long period of time. Today, start by getting comfortable with the platform.\n",
    "\n",
    "You do not need to be a Python programmer. The syntax of the Python language can be intuitive if you are new to it. Just like other languages, focus on function calls (e.g. function()) and assignments (e.g. a = “b”). This will get you most of the way. You are a developer; you know how to pick up the basics of a language really fast. Just get started and dive into the details later.\n",
    "You do not need to be a deep learning expert. You can learn about the benefits and limitations of various algorithms later, and there are plenty of tutorials that you can read to brush up on the steps of a deep learning project.\n",
    "\n",
    "但是，你需要提前了解以下知识：\n",
    "* Python 基础，例如 class 和 function 的知识。\n",
    "* 深度学习的基本概念，例如关于什么是训练集和测试集，什么是神经网络。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实践<a id='practice'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 安装 PyTorch "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. 验证 PyTorch 安装并查看版本\n",
    "\n",
    "安装 PyTorch 后，确认库已成功安装并且您可以开始使用它。 \n",
    "\n",
    "不要跳过此步骤。 \n",
    "\n",
    "如果 PyTorch 未正确安装或在此步骤中引发错误，则将无法运行之后的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # torch.__version__ 返回安装的 PyTorch 的版本号"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 建立 PyTorch 深度学习模型\n",
    "\n",
    "在本节中，您将了解深度学习模型的生命周期以及可用于定义模型的 PyTorch API。 \n",
    "\n",
    "模型有一个生命周期，这个非常简单的知识为数据集建模和理解 PyTorch API 提供了支柱。 \n",
    "\n",
    "生命周期中的五个步骤如下： \n",
    "\n",
    "1. 准备数据。 \n",
    "2. 定义模型。 \n",
    "3. 训练模型。 \n",
    "4. 评估模型。 \n",
    "5. 做出预测。 \n",
    "\n",
    "注意：使用 PyTorch API 有很多方法可以实现这些步骤，我的目标是向您展示最简单、最常见或最惯用的方法。 \n",
    "\n",
    "如果您发现更好的方法，请在下面的评论中告诉我。\n",
    "\n",
    "接下来让我们依次仔细看看每个步骤。 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 准备数据\n",
    "\n",
    "第一步是加载和准备数据。 \n",
    "\n",
    "神经网络模型需要数值输入数据和数值输出数据。 \n",
    "\n",
    "您可以使用标准 Python 库来加载和准备表格数据，例如 CSV 文件。例如，Pandas 可用于加载您的 CSV 文件，scikit-learn 中的工具可用于编码分类数据，例如类标签。\n",
    "\n",
    "PyTorch 提供了 Dataset 类，您可以扩展和自定义该类以加载您的数据集。 \n",
    "\n",
    "例如，数据集对象的构造函数可以加载您的数据文件（例如 CSV 文件）。然后，您可以覆盖可用于获取数据集长度（行数或样本数）的 `__len__()` 函数，以及用于按索引获取特定样本的 `__getitem__()` 函数。 \n",
    "\n",
    "加载数据集时，您还可以执行任何所需的转换，例如缩放或编码。 \n",
    "\n",
    "下面提供了自定义数据集类的框架。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# dataset definition\n",
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载后，PyTorch 提供 DataLoader 类，用于在模型训练和评估期间导航数据集实例。 \n",
    "\n",
    "可以为训练数据集、测试数据集甚至验证数据集创建 DataLoader 实例。 \n",
    "\n",
    "random_split（） 函数可用于将数据集拆分为训练集和测试集。拆分后，可以将数据集中的行选择提供给 DataLoader，以及批大小以及是否应在每个纪元对数据进行随机排序。 \n",
    "\n",
    "例如，我们可以通过传入数据集中的选定行样本来定义 DataLoader。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "\n",
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer = Linear(n_inputs, 1)\n",
    "        self.activation = Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        X = self.layer(X)\n",
    "        X = self.activation(X)\n",
    "        return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义后，可以循环 *DataLoader*，每次迭代生成一批样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "for i, (inputs, targets) in enumerate(train_dl):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ('Spring', 'Green')), (2, ('Summer', 'Red')), (3, ('Fall', 'Yellow')), (4, ('Winter', 'White'))]\n",
      "My impression 1 about Spring is Green.\n",
      "My impression 2 about Summer is Red.\n",
      "My impression 3 about Fall is Yellow.\n",
      "My impression 4 about Winter is White.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)\n",
    "组合为一个有索引的序列，同时列出数据和数据下标。多用在 for 循环中。\n",
    "以下为一个简单示例。\n",
    "'''\n",
    "\n",
    "seasons = [('Spring', 'Green'), \n",
    "           ('Summer', 'Red'), \n",
    "           ('Fall', 'Yellow'), \n",
    "           ('Winter', 'White')\n",
    "           ]\n",
    "print(list(enumerate(seasons, start=1)))  # start 参数设置序列从 1 开始，不填则默认从 0 开始\n",
    "# 再在 for 循环中看看 enumerate 函数的效果\n",
    "for i, (season, color) in enumerate(seasons, start=1):\n",
    "    print(f'My impression {i} about {season} is {color}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 为预测任务建立 PyTorch 深度学习模型\n",
    "\n",
    "在本节中，您将了解如何使用标准深度学习模型（包括多层感知器 （Multi Layer Perceptrons, MLP） 和卷积神经网络 （Convolutional Neural Networks, CNN））进行开发、评估和预测。\n",
    "\n",
    "多层感知器模型（MLP）是一种标准的全连接神经网络模型。 \n",
    "\n",
    "它由节点层组成，其中每个节点连接到前一层的所有输出，每个节点的输出连接到下一层节点的所有输入。 \n",
    "\n",
    "MLP 是具有一个或多个完全连接层的模型。此模型适用于表格数据，即在表或电子表格中查找的数据，每个变量一列，每个变量一行。您可能想使用 MLP 探索三个预测建模问题;它们是二元分类、多类分类和回归。 \n",
    "\n",
    "让我们在真实数据集上为每种情况拟合一个模型。 \n",
    "\n",
    "注意：本节中的模型有效，但未优化。看看你是否可以提高他们的表现。在下面的评论中发布您的发现。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. 建立二分类感知机\n",
    "\n",
    "我们将使用电离层二分类数据集来演示用于二分类的 MLP。 \n",
    "\n",
    "该数据集涉及预测大气中是否存在给定雷达回波的结构。 \n",
    "\n",
    "数据集将使用 Pandas 自动下载，但您可以在此处了解更多信息：\n",
    "\n",
    "- Ionosphere Dataset (csv).\n",
    "- Ionosphere Dataset Description.\n",
    "\n",
    "我们将使用 LabelEncoder 将字符串标签编码为整数值 0 和 1。该模型将适合 67% 的数据，其余 33% 将用于评估，使用 train_test_split() 函数进行拆分。 \n",
    "\n",
    "使用带有“He Uniform”权重初始化的“relu”激活是一个很好的做法。这种组合对于克服训练深度神经网络模型时梯度消失的问题大有帮助。有关 ReLU 的更多信息，请参阅教程： \n",
    "\n",
    "- 简单介绍整流线性单元 (ReLU) 该模型预测类别 1 的概率并使用 sigmoid 激活函数。\n",
    "\n",
    "该模型使用随机梯度下降进行优化，并力求最小化二元交叉熵损失。 下面列出了完整的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 116\n",
      "Accuracy: 0.905\n",
      "Predicted: 0.999 (class=1)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch mlp for binary classification\n",
    "# \n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    " \n",
    "# dataset definition\n",
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path, header=None)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    "        # label encode target and ensure the values are floats\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])\n",
    " \n",
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden3 = Linear(8, 1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n",
    " \n",
    "# prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl\n",
    " \n",
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = BCELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(100):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    " \n",
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc\n",
    " \n",
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat\n",
    " \n",
    "# prepare the data\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))\n",
    "# define the network\n",
    "model = MLP(34)\n",
    "# train the model\n",
    "train_model(train_dl, model)\n",
    "# evaluate the model\n",
    "acc = evaluate_model(test_dl, model)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "# make a single prediction (expect class=1)\n",
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = predict(row, model)\n",
    "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行示例首先报告训练数据集和测试数据集的形状，然后拟合模型并在测试数据集上对其进行评估。最后，对单行数据进行预测。 \n",
    "\n",
    "注意：根据算法或评估过程的随机性质或数值精度的差异，您的结果可能会有所不同。请考虑运行几次示例并比较平均结果。 \n",
    "\n",
    "你得到了什么结果？ \n",
    "\n",
    "你能改变模型做得更好吗？\n",
    "\n",
    "你可以试着修改代码以直接输出平均结果吗？\n",
    "\n",
    "**不要犹豫，试试直接在 Bohrium Notebook 中实现你的想法。**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
