{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速开始 PyTorch｜使用 Python 建立深度学习模型\n",
    "\n",
    "> 作者: Haohui Que [quehaohui@dp.tech](mailto:quehaohui@dp.tech)\n",
    ">\n",
    "> 创建日期: 2023-03-11 19:13\n",
    ">\n",
    "> 最后一次修改: Haohui Que [quehaohui@dp.tech](mailto:quehaohui@dp.tech), \n",
    ">\n",
    "> 最后一次修改时间: 2023-03-12 18:36\n",
    ">\n",
    "> 目录: /Proem/PyTorch_Deep_Learning_Model_Tutorial\n",
    ">\n",
    "> 描述: 本教程参考于[1]，可在 Bohrium Notebook 上直接运行，您可以点击界面上方蓝色按钮 `开始连接`，选择 `notebook-pytorch:1.13.0` 镜像及任何一款计算机型，稍等片刻即可运行。\n",
    "> 如您遇到任何问题，请您联系 [bohrium@dp.tech](mailto:bohrium@dp.tech) 。\n",
    ">\n",
    "> 共享协议: 本作品采用[知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议](https://creativecommons.org/licenses/by-nc-sa/4.0/)进行许可。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目标\n",
    "\n",
    "> **掌握使用 PyTorch 建立深度学习模型的范式周期，并跟随完整案例学习如何应用于预测任务。**\n",
    "\n",
    "在学习本教程后，您将能够：\n",
    "\n",
    "- 初识 PyTorch，安装 PyTorch 并验证其运行。\n",
    "\n",
    "- 通过五个步骤了解建立、拟合和验证 PyTorch 模型的范式周期。\n",
    "\n",
    "- 掌握如何为回归、分类预测任务建立 PyTorch 深度学习模型。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "\n",
    "* [背景知识](#background)\n",
    "* [实践](#practice)\n",
    "  * [1 初识 PyTorch](#whatispytorch)\n",
    "    * [1.1 Torch 与 PyTorch](#1-1)\n",
    "    * [1.2 安装 PyTorch【Bohrium 中可直接运行，无需安装】](#1-2)\n",
    "    * [1.3 验证安装并查看 PyTorch 版本](#1-3)\n",
    "  * 2 [PyTorch 深度学习模型的建立范式](#pytorchdeeplearningmodellife-cycle)\n",
    "    * [2.1 准备数据](#2-1)\n",
    "    * [2.2 定义模型](#2-2)\n",
    "    * [2.3 训练模型](#2-3)\n",
    "    * [2.4 验证模型](#2-4)\n",
    "    * [2.5 做出预测](#2-5)\n",
    "  * 3 [为预测任务建立 PyTorch 深度学习模型](#developpytorchdeeplearningmodels)\n",
    "    * 3.1 How to Develop an MLP for Binary Classification\n",
    "    * 3.2 How to Develop an MLP for Multiclass Classification\n",
    "    * 3.3 How to Develop an MLP for Regression\n",
    "    * 3.4 How to Develop a CNN for Image Classification\n",
    "* [总结](#summary)\n",
    "* [推荐阅读](#furtherreading)\n",
    "* [参考](references)\n",
    "\n",
    "**阅读该教程【最多】约需 60 分钟。**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 背景知识<a id ='background'></a>\n",
    "\n",
    "**您不需要理解所有的事（至少目前是）。** 您的目标是从头到尾完成本教程并获得结果。您不需要在第一次尝试时就了解所有内容。边学习边写下您的问题。使用丰富的 API 文档来了解您正在使用的所有功能。\n",
    "\n",
    "**您不需要精通数学原理。** 数学是描述算法如何工作的紧凑方式，特别是线性代数、概率和微积分的工具。这些并不是您可以用来了解算法如何工作的唯一工具。您还可以使用代码并探索具有不同输入和输出的算法行为。了解数学不会告诉您选择哪种算法或如何最好地配置它。您只能通过精心控制的实验来发现这一点。\n",
    "\n",
    "**您不需要知道算法是如何工作的。** 了解限制以及如何配置深度学习算法非常重要。但是学习算法可以稍后进行。您需要在很长一段时间内慢慢建立这种算法知识。今天，首先要熟悉这个平台。\n",
    "\n",
    "**您不需要精通 Python。** 如果您不熟悉 Python 语言，不要担心，Python 的语法是直观的。就像其他语言一样，您只需要专注于函数调用（例如 function（））和赋值（例如 a = “b”）（这已包括了大部分使用场景）。只需开始，稍后再深入了解详细信息。\n",
    "\n",
    "**您不需要成为深度学习专家。** 您可以稍后了解各种算法的优点和局限性，并且您可以阅读大量教程来复习深度学习项目的步骤。\n",
    "\n",
    "**您只需要提前了解以下基础知识：**\n",
    "* Python 基础，例如 *class* 和 *function* 的知识。如果您不了解，推荐阅读：\n",
    "    - [Python 函数式编程](https://www.liaoxuefeng.com/wiki/1016959663602400/1017328525009056)\n",
    "    - [Python 类和实例](https://www.liaoxuefeng.com/wiki/1016959663602400/1017496031185408)\n",
    "* 深度学习的基本概念，例如关于什么是特征和标签、训练集和测试集，什么是神经网络。如果您不了解，推荐阅读：\n",
    "    - [什么是神经网络]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实践 <a id='practice'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 初识 PyTorch <a id='whatispytorch'></a>\n",
    "\n",
    "在这一部分，你会了解什么是 PyTorch，在 Bohrium 中使用 PyTorch，验证并查看版本。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 什么是 PyTorch [1] <a id='1-1'></a>\n",
    "\n",
    "[PyTorch](https://github.com/pytorch/pytorch) 是由 Facebook 开发和维护的用于深度学习的开源 Python 库。 \n",
    "\n",
    "该项目于 2016 年启动，并迅速成为开发人员和研究人员中流行的框架。 \n",
    "\n",
    "[Torch](https://github.com/torch/torch7) (*Torch7*) 是一个用 C 编写的用于深度学习的开源项目，通常通过 Lua 接口使用。它是 PyTorch 的前身项目，不再积极开发。 PyTorch 在名称中包含 *“Torch”* 以感谢先前的 torch 库，使用 *\"Py\"* 作为前缀以表明聚焦于 Python。 \n",
    "\n",
    "PyTorch API 简单灵活，使其成为学术界和研究人员开发新的深度学习模型和应用程序的最爱之一。同时，广泛的应用衍生了许多针对特定应用（例如文本、计算机视觉和音频数据）的扩展，并且可作为预训练模型直接使用。因此，它可能是学术界使用最多的库。 \n",
    "\n",
    "与 [Keras](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/) 等更简单的界面相比，PyTorch 的灵活性是以易用性为代价的，尤其是对于初学者而言。选择 PyTorch 而不是 Keras 的意味着放弃了一些易用性、需要面对更陡峭的学习曲线、以及使用更多的代码以获得更大的灵活性，也许还有一个更有活力的学术社区。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 安装 Pytorch <a id='1-2'></a>\n",
    "\n",
    "**Bohrium 已默认安装 PyTorch，可在 Notebook 上直接运行。** \n",
    "\n",
    "您可以点击界面上方蓝色按钮 `开始连接`，选择 `notebook-pytorch:1.13.0` 镜像及任何一款计算机型，稍等片刻即可运行。\n",
    "\n",
    "如果您的 Bohrium 镜像尚未安装 PyTorch， 也可快速通过 pip 安装 torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您需要使用更特定于您的平台或包管理器的安装方法，您可以在[这里](https://pytorch.org/get-started/locally/)查看更完整的安装说明。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 验证 PyTorch 安装并查看版本 <a id='1-3'></a>\n",
    "\n",
    "安装 PyTorch 后，确认库已成功安装并且您可以开始使用它。 \n",
    "\n",
    "不要跳过此步骤。 \n",
    "\n",
    "如果 PyTorch 未正确安装或在此步骤中引发错误，则将无法运行之后的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # torch.__version__ 返回安装的 PyTorch 的版本号"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 PyTorch 深度学习模型的建立范式 <a id='pytorchdeeplearningmodellife-cycle'></a>\n",
    "\n",
    "在本节中，您将了解深度学习模型的建立范式以及可用于定义模型的 PyTorch API。 \n",
    "\n",
    "建立模型有一个范式，这个非常简单的知识为数据集建模和理解 PyTorch API 提供了支撑。 \n",
    "\n",
    "模型建立范式中的五个步骤如下： \n",
    "\n",
    "1. 准备数据。 \n",
    "2. 定义模型。 \n",
    "3. 训练模型。 \n",
    "4. 评估模型。 \n",
    "5. 做出预测。 \n",
    "\n",
    "注意：使用 PyTorch API 有很多方法可以实现这些步骤，我们的目标是向您展示最简单、最常见或最惯用的方法。 \n",
    "\n",
    "如果您发现更好的方法，请通过邮箱告诉我。\n",
    "\n",
    "接下来让我们依次仔细看看每个步骤。 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 准备数据 <a id='2-1'></a>\n",
    "\n",
    "\n",
    "第一步是加载和准备数据。 \n",
    "\n",
    "神经网络模型需要输入数据和输出数据。 \n",
    "\n",
    "您可以使用标准 Python 库来加载和准备多维数据，例如 CSV 文件。\n",
    "\n",
    "Pandas 可用于加载您的 CSV 文件，scikit-learn 中的工具可用于编码分类数据，例如对标签分类。\n",
    "\n",
    "PyTorch 提供了 Dataset 类，您可以扩展和自定义该类以加载您的数据集。 \n",
    "\n",
    "例如，数据集对象的构造函数可以加载您的数据文件（例如 CSV 文件）。然后，您可以覆盖可用于获取数据集长度（行数或样本数）的 `__len__()` 函数，以及用于按索引获取特定样本的 `__getitem__()` 函数。 \n",
    "\n",
    "加载数据集时，您还可以执行任何所需的转换，例如缩放或编码。 \n",
    "\n",
    "下面提供了自定义数据集类的框架。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# dataset definition\n",
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载后，PyTorch 提供 *DataLoader* 类，用于在模型训练和评估期间导航数据集实例。 \n",
    "\n",
    "可以为训练数据集、测试数据集甚至验证数据集创建 *DataLoader* 实例。 \n",
    "\n",
    "`random_split()` 函数可用于将数据集拆分为训练集和测试集。拆分后，将数据集中的选定条目及其大小提供给 *DataLoader*，并可选择是否根据不同数据划分对数据进行随机排序。 \n",
    "\n",
    "例如，我们可以通过传入数据集行中的选定样本来定义 *DataLoader*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "\n",
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer = Linear(n_inputs, 1)\n",
    "        self.activation = Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        X = self.layer(X)\n",
    "        X = self.activation(X)\n",
    "        return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义后，可以循环 *DataLoader*，每次迭代生成一批样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "for i, (inputs, targets) in enumerate(train_dl):  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enumerate() 函数是 Python 内置函数，用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个有索引的序列，同时列出数据和数据下标。多用在 for 循环中。\n",
    "\n",
    "尝试在本 Notebook 中运行以下示例并理解 enumerate() 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ('Spring', 'Green')), (2, ('Summer', 'Red')), (3, ('Fall', 'Yellow')), (4, ('Winter', 'White'))]\n",
      "--------\n",
      "My impression 1 about Spring is Green.\n",
      "My impression 2 about Summer is Red.\n",
      "My impression 3 about Fall is Yellow.\n",
      "My impression 4 about Winter is White.\n"
     ]
    }
   ],
   "source": [
    "seasons = [('Spring', 'Green'), \n",
    "           ('Summer', 'Red'), \n",
    "           ('Fall', 'Yellow'), \n",
    "           ('Winter', 'White')\n",
    "           ]\n",
    "print(list(enumerate(seasons, start=1)))  # start 参数设置序列从 1 开始，不填则默认从 0 开始\n",
    "print('--------')\n",
    "\n",
    "# 再在 for 循环中看看 enumerate 函数的效果\n",
    "for i, (season, color) in enumerate(seasons, start=1):\n",
    "    print(f'My impression {i} about {season} is {color}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 定义模型 <a id='2-2'></a>\n",
    "\n",
    "下一步是定义模型。 \n",
    "\n",
    "在 PyTorch 中定义模型的习惯用法是定义一个继承 [Module 类]((https://pytorch.org/docs/stable/nn.html#module))的 *Python class* 。\n",
    "\n",
    "您构造的类定义了模型的层，`forward()` 函数需要覆写以定义在模型层中的输入参数的前向传播。\n",
    "\n",
    "许多层都可用，例如用于全连接层的 [Linear](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear)，用于卷积层的 [Conv2d](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d)，用于池化层的 [MaxPool2d](https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d)。\n",
    "\n",
    " 激活函数也可以定义为层，例如 [ReLU](https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU), [Softmax](https://pytorch.org/docs/stable/nn.html#torch.nn.Softmax), 和 [Sigmoid](https://pytorch.org/docs/stable/nn.html#torch.nn.Sigmoid).\n",
    "\n",
    " 下面是一个简单的单层 MLP 模型的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer = Linear(n_inputs, 1)\n",
    "        self.activation = Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        X = self.layer(X)\n",
    "        X = self.activation(X)\n",
    "        return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在构造函数中定义给定层后，也可以初始化给定层的权重。 \n",
    "\n",
    "常见的例子包括 [Xavier](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_) 和 [He weight](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_)  权重初始化方案。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "xavier_uniform_(self.layer.weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 训练模型 <a id='2-3'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 评估模型 <a id='2-4'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 做出预测 <a id='2-5'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 为预测任务建立 PyTorch 深度学习模型 <a id='developpytorchdeeplearningmodels'></a>\n",
    "\n",
    "在本节中，您将了解如何使用标准深度学习模型（包括多层感知器 （Multi Layer Perceptrons, MLP） 和卷积神经网络 （Convolutional Neural Networks, CNN））进行开发、评估和预测。\n",
    "\n",
    "多层感知器模型（MLP）是一种标准的全连接神经网络模型。 \n",
    "\n",
    "它由节点层组成，其中每个节点连接到前一层的所有输出，每个节点的输出连接到下一层节点的所有输入。 \n",
    "\n",
    "MLP 是具有一个或多个完全连接层的模型。此模型适用于表格类型的数据。您可能想使用 MLP 探索三个预测建模问题;它们是二元分类、多类分类和回归。让我们在真实数据集上为每种情况拟合一个模型。 \n",
    "\n",
    "注意：本节中的模型有效，但未优化。看看您是否可以提高他们的表现。<span style='color:orange; font-weight:bold'>不要犹豫，试试直接在 Bohrium Notebook 中实现您的想法。</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 建立二分类感知机\n",
    "\n",
    "我们将使用电离层二分类数据集来演示用于二分类的 MLP。 \n",
    "\n",
    "该数据集涉及预测大气中是否存在给定雷达回波的结构。 \n",
    "\n",
    "数据集将使用 Pandas 自动下载，但您可以在此处了解更多信息：\n",
    "\n",
    "- [Ionosphere Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv).\n",
    "- [Ionosphere Dataset Description](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.names).\n",
    "\n",
    "我们将使用 [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) 将字符串标签编码为整数值 0 和 1。该模型将适合 67% 的数据，其余 33% 将用于评估，使用 [train_test_split() function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) 函数进行拆分。 \n",
    "\n",
    "使用带有 *“He Uniform”* 权重初始化的 *“relu”* 激活函数是一个很好的做法。这种组合对于克服训练深度神经网络模型时[梯度消失](https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/) 的问题大有帮助。有关 ReLU 的更多信息，请参阅教程： \n",
    "\n",
    "- [A Gentle Introduction to the Rectified Linear Unit (ReLU)](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)\n",
    "\n",
    "该模型使用随机梯度下降进行优化，并力求最小化[二元交叉熵损失](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)。 下面列出了完整的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch mlp for binary classification\n",
    "# \n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    " \n",
    "# dataset definition\n",
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path, header=None)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    "        # label encode target and ensure the values are floats\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])\n",
    " \n",
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden3 = Linear(8, 1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n",
    " \n",
    "# prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl\n",
    " \n",
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = BCELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(100):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    " \n",
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc\n",
    " \n",
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat\n",
    " \n",
    "# prepare the data\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))\n",
    "# define the network\n",
    "model = MLP(34)\n",
    "# train the model\n",
    "train_model(train_dl, model)\n",
    "# evaluate the model\n",
    "acc = evaluate_model(test_dl, model)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "# make a single prediction (expect class=1)\n",
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = predict(row, model)\n",
    "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行示例首先报告训练数据集和测试数据集的形状，然后拟合模型并在测试数据集上对其进行评估。最后，对单行数据进行预测。 \n",
    "\n",
    "注意：根据算法或评估过程的随机性质或数值精度的差异，您的结果可能会有所不同。请考虑运行几次示例并比较平均结果。 \n",
    "\n",
    "您得到了什么结果？ \n",
    "\n",
    "您能改变模型做得更好吗？\n",
    "\n",
    "您可以试着修改代码以直接输出平均结果吗？\n",
    "\n",
    "<span style='color:orange; font-weight:bold'>不要犹豫，试试直接在 Bohrium Notebook 中实现您的想法。</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
